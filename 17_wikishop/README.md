## Определение токсичных комментариев
### Постановка задачи
Проект создан в интересах Викишоп; цель работы - разработать модель, способную определять негативные комментарии в описании продукта.

Ключевая метрика качества предсказания модели - f1_score - среднегармоническое полноты и точности. Задача достичь f1_score не ниже 0.75.

### Исходный датасет
Датасет для обучения модели был предоставлен Викишоп. Исходный датасет содержит 159292 строк и две информативные колонки. В их числе колонка 'text', которая содержит обучающий признак - он преставляет собой текст твита. Целевой признак находится в колонке 'toxic', он содержит маркер токсичности текста (1 или 0).

Типы данных соответствуют содержимому колонок. Датасет пригоден к дальнейшей работе.

В датасете сильный дисбаланс классов, положительный (токсичный) класс - 10%.

В ходе работы датасет был использован без учета дисбаланса классов, однако, если его учесть, возможно удастся повысить метрику модели.

### Обучение моделей
Были испробованы три модели: BERT без дообучения, BERT c дообучением на датасете заказчика и ToxicBERT, специально обученная на большом датасете с похожей задачей.

#### DistilBERT без дообучения
Модель DistilBERT без дообучения показала плохой результат. Качество предсказаний модели через pipeline на валидации имеет f1_score = 0.1.

При подборе порога для положительного класса удается достичь f1_score = 0.1945 или 0.2525, однако эти значения неприемлемо низкие. 

Без дообучения модель DistilBERT не пригодна для решения задачи.


#### DistilBERT, обученная на предоставленном датасете
Поскольку модель в исходном виде имеет крайне низкое качество предсказаний, была предпринята попытка дообучить модель на датасете заказчика. 

Для этого из исходного датасета были выделены обучающий и тестовый датасеты размером 3000 и 500 записей соответственно. Датасеты были сформированы без учета дисбаланса классов.

Модель была обучена на тренировочном датасете в течение двух эпох с learning_rate = 2e-5. 

Обученная модель была сохранена в личном аккаунте на huggingface.co . В ходе создания датасетов, обучения модели и предсказаний были использованы высокоуровневые инструменты huggingface.co .

Предсказания дообученной модели имеют ключевую метрику f1_score = 0.79, что значительно выше, чем метрика модели "из коробки", и соответствует условию задания.

#### ToxicBERT
Была также опробована модель ToxicBERT original, разработанная на основе BERT и обученная на большом датасете специально для задачи определения токсичных комментариев. К сожалению, модель очень ресурсозатратная, опробовать ее на репрезентативном валидационном датасете не получилось. 

На валидационном датасете из 20 записей результат получился хороший: попадание 20 из 20 при пороге ниже 0.2. Максимальный f1_score = 1.0, однако делать выводы на основании датасета из 20 записей нельзя.

С этой моделью получен самый высокий f1_score, однако чтоб сделать вывод о пригодности этой модели без дообучения для решения поставленной задачи, нужно провести эксперимент на валидационном датасете достаточного размера.

### Выбор лучшей модели
Оптимальным выглядит результат ToxicBERT, однако он получен на нерепрезентативном валидационном датасете (модель слишком ресурсоемкая, не удалось запустить на датасете большего размера).

Поэтому в качестве лучшей модели выберем модель BERT, дообученную на датасете заказчика.

На тестовой выборк метрика f1_score лучшей модели - 0.785

### Вывод и дальнейшие рекомендации
Модель DistilBERT, дообученная на датасете заказчика, показала приемлемый результат работы. Она рекомендована к дальнейшей доработке. 

Можно попробовать обучить ее на датасете большего размера, в течение большего количества эпох. Кроме того, можно попробовать учесть дисбаланс классов при формировании обучающего датасета, доведя долю положительного класса примерно до половины.

Кроме этого имеет смысл привлечь больше ресурсов и провести более детальный эксперимент с моделями ToxicBERT - возможно, этот вариант окажется более оптимальным.

